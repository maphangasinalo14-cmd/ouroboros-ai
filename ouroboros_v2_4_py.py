# -*- coding: utf-8 -*-
"""ouroboros_v2.4.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11mJaOjigBgYn7zTK5h7Mgr8sb_YHjT5R
"""

# ==========================================
# üêç OUROBOROS v2.4: ROBUST MODEL FINDER
#    (Automatically finds the working AI Model)
# ==========================================

import subprocess
import sys

# 1. Install & Import
def install(package):
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-U", "google-generativeai"])

try:
    import google.generativeai as genai
except ImportError:
    print("[*] Installing Google Gemini AI SDK...")
    install("google-generativeai")
    import google.generativeai as genai

import time
import requests
import os
import signal
import re
import json
import logging
from datetime import datetime

# üî¥ KEY PRE-LOADED
GEMINI_API_KEY = "AIzaSyDtIauwZftygGGHQWa3PLpWTyhO-mLWrMU"

# CONFIG
PORT = 5002
APP_FILE = "vulnerable_app.py"

# ==========================================
# üõ†Ô∏è HELPER FUNCTIONS
# ==========================================

def log(msg, icon="‚ÑπÔ∏è"):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {icon} {msg}")

def create_vulnerable_app():
    code = f"""
from flask import Flask, request, jsonify
import sqlite3
import logging

app = Flask(__name__)
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)

def init_db():
    conn = sqlite3.connect(':memory:', check_same_thread=False)
    c = conn.cursor()
    c.execute('CREATE TABLE users (username TEXT, password TEXT)')
    c.execute("INSERT INTO users VALUES ('admin', 'supersecret')")
    conn.commit()
    return conn

db = init_db()

@app.route('/login', methods=['POST'])
def login():
    username = request.form.get('username', '')
    query = f"SELECT * FROM users WHERE username = '{{username}}'"
    try:
        cursor = db.execute(query)
        user = cursor.fetchone()
        if user: return jsonify({{"status": "success", "msg": f"Welcome {{user[0]}}!"}}), 200
        else: return jsonify({{"status": "fail"}}), 401
    except Exception as e: return jsonify({{"status": "error"}}), 500

if __name__ == '__main__':
    app.run(port={PORT})
"""
    with open(APP_FILE, 'w') as f:
        f.write(code)

def start_server():
    subprocess.run(["pkill", "-f", APP_FILE])
    time.sleep(1)
    proc = subprocess.Popen([sys.executable, APP_FILE],
                          stdout=subprocess.DEVNULL,
                          stderr=subprocess.DEVNULL)
    time.sleep(3)
    return proc

def test_vulnerability():
    try:
        payload = "admin' OR '1'='1"
        res = requests.post(f"http://127.0.0.1:{PORT}/login", data={'username': payload}, timeout=3)
        if "Welcome" in res.text: return True
    except: pass
    return False

# ==========================================
# üß† SMART MODEL SELECTOR
# ==========================================

def get_working_model():
    """Loops through known model names to find one that works"""
    genai.configure(api_key=GEMINI_API_KEY)

    # Priority list of models to try
    candidates = [
        'gemini-1.5-flash',
        'gemini-1.5-flash-latest',
        'gemini-pro',
        'gemini-1.0-pro',
        'models/gemini-1.5-flash'
    ]

    log("Testing AI connectivity...", "üì°")

    # Method A: Try to list models first (Best practice)
    try:
        available = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available.append(m.name)

        if available:
            # Return the first text-generation model found
            log(f"Found available models: {available}", "‚úÖ")
            # Prefer flash if available, otherwise take the first one
            for m in available:
                if 'flash' in m: return genai.GenerativeModel(m)
            return genai.GenerativeModel(available[0])

    except Exception as e:
        log(f"ListModels failed ({e}), falling back to manual trial...", "‚ö†Ô∏è")

    # Method B: Brute force try if listing fails
    for name in candidates:
        try:
            log(f"Trying model: {name}...", "‚è≥")
            model = genai.GenerativeModel(name)
            # Test it with a tiny prompt
            model.generate_content("Hi")
            log(f"Connected to {name}!", "‚úÖ")
            return model
        except:
            continue

    return None

def apply_ai_patch():
    model = get_working_model()
    if not model:
        log("Could not connect to ANY Google AI models. Check API Key.", "‚ùå")
        return False

    with open(APP_FILE, 'r') as f:
        vulnerable_code = f.read()

    prompt = f"""
    You are a Security Bot.
    TASK: Fix SQL Injection in this Python code.
    CODE:
    ```python
    {vulnerable_code}
    ```
    INSTRUCTIONS:
    1. Change f-string query to parameterized query (using ?).
    2. Change db.execute(query) to db.execute(query, (username,))
    3. Return ONLY valid python code. No backticks.
    """

    try:
        log("Sending code to AI...", "üì§")
        response = model.generate_content(prompt)

        # DEBUG PRINT
        print("\n" + "="*20 + " AI RESPONSE " + "="*20)
        print(response.text[:200] + "...")
        print("="*53 + "\n")

        patched_code = response.text.replace("```python", "").replace("```", "").strip()

        if "?" not in patched_code:
            log("AI failed to fix the query parameters.", "‚ùå")
            return False

        with open(APP_FILE, 'w') as f:
            f.write(patched_code)

        log("Patch Written to Disk.", "‚úÖ")
        return True

    except Exception as e:
        log(f"AI Generation Error: {e}", "‚ùå")
        return False

# ==========================================
# üé¨ MAIN
# ==========================================

def main():
    print("üêç OUROBOROS v2.4: ROBUST EDITION")

    log("Deploying App...", "üèóÔ∏è")
    create_vulnerable_app()
    proc = start_server()

    if test_vulnerability():
        log("App is VULNERABLE.", "‚öîÔ∏è")
    else:
        log("App setup failed.", "‚ùå")
        if proc: proc.kill()
        return

    log("Starting Patch Sequence...", "üöë")
    if proc: proc.kill()

    if apply_ai_patch():
        log("Redeploying Patched App...", "üîÑ")
        proc = start_server()

        if test_vulnerability():
            log("FAILURE: Patch didn't work.", "‚ùå")
        else:
            log("SUCCESS: Vulnerability Neutralized!", "üèÜ")

            # Show the proof
            with open(APP_FILE, 'r') as f:
                content = f.read()
                if "?" in content:
                    print("\nPROOF OF FIX (Parameterized Query found):")
                    for line in content.splitlines():
                        if "?" in line: print(f"  -> {line.strip()}")
    else:
        log("Patching failed.", "‚ùå")

    if proc: proc.kill()

if __name__ == "__main__":
    main()